{
  "name": "datadog-triggered-incident-workflow-dag",
  "description": "Dynamic Production incident response workflow with AI investigation and Slack integration powered by Kubiya workflows - https://docs.kubiya.ai",
  "params": {
    "incident_id": "$INCIDENT_PUBLIC_ID",
    "incident_title": "$INCIDENT_TITLE",
    "incident_severity": "$INCIDENT_SEVERITY",
    "incident_priority": "High",
    "incident_body": "$INCIDENT_MSG",
    "incident_url": "$INCIDENT_URL",
    "incident_source": "datadog",
    "incident_owner": "devops",
    "slack_channel_id": "#inc-$INCIDENT_PUBLIC_ID-$INCIDENT_TITLE",
    "max_retries": "3",
    "customer_impact": "UNKNOWN",
    "affected_services": "NA",
    "datadog_environment": "$TAGS[environment]",
    "dd_environment": "na",
    "k8s_environment": "${agent_mapping.DYNAMIC_K8S_ENV}",
    "agent_uuid": "${agent_mapping.DYNAMIC_AGENT_UUID}",
    "normalize_channel_name": "true",
    "region": "${agent_mapping.DYNAMIC_REGION}",
    "region_name": "${agent_mapping.DYNAMIC_REGION_NAME}",
    "region_emoji": "${agent_mapping.DYNAMIC_REGION_EMOJI}",
    "investigation_agent_name": "${agent_mapping.DYNAMIC_AGENT_NAME}"
  },
  "env": {
    "KUBIYA_USER_EMAIL": "${KUBIYA_USER_EMAIL}",
    "KUBIYA_API_KEY": "${KUBIYA_API_KEY}",
    "KUBIYA_USER_ORG": "${KUBIYA_USER_ORG}",
    "KUBIYA_AUTOMATION": "1",
    "INCIDENT_SEVERITY": "medium",
    "INCIDENT_PRIORITY": "medium"
  },
  "steps": [
    {
      "name": "map-environment-to-agent",
      "command": "echo \"üîÑ MAPPING ENVIRONMENT TO AGENT\"\necho \"==============================\"\necho \"Datadog Environment: ${datadog_environment}\"\n\n# Map environment to agent configuration\ncase \"${datadog_environment}\" in\n  \"eu-production\")\n    AGENT_UUID=\"dd354944-fd6f-404c-bf67-090d7e8cfe60\"\n    AGENT_NAME=\"chatops-eu\"\n    REGION=\"EU\"\n    REGION_NAME=\"Europe\"\n    REGION_EMOJI=\"üá™üá∫\"\n    K8S_ENV=\"p44-eu-prod\"\n    ;;\n  \"na-production\")\n    AGENT_UUID=\"9c6c370c-e289-411f-9c06-2cacc5d10153\"\n    AGENT_NAME=\"chatops-na\"\n    REGION=\"NA\"\n    REGION_NAME=\"North-America\"\n    REGION_EMOJI=\"üåé\"\n    K8S_ENV=\"p44-na-prod\"\n    ;;\n  \"na-integration\")\n    AGENT_UUID=\"20a1366f-4c82-4041-bd9d-29b635b98554\"\n    AGENT_NAME=\"chatops-na-integration\"\n    REGION=\"NA-INT\"\n    REGION_NAME=\"North-America-Integration\"\n    REGION_EMOJI=\"üß™\"\n    K8S_ENV=\"p44-na-integration\"\n    ;;\n  *)\n    echo \"‚ö†Ô∏è Unknown environment: ${datadog_environment}, defaulting to NA production\"\n    AGENT_UUID=\"9c6c370c-e289-411f-9c06-2cacc5d10153\"\n    AGENT_NAME=\"chatops-na\"\n    REGION=\"NA\"\n    REGION_NAME=\"North-America\"\n    REGION_EMOJI=\"üåé\"\n    K8S_ENV=\"p44-na-prod\"\n    ;;\nesac\n\necho \"Selected Configuration:\"\necho \"  Agent UUID: ${AGENT_UUID}\"\necho \"  Agent Name: ${AGENT_NAME}\"\necho \"  Region: ${REGION}\"\necho \"  Region Name: ${REGION_NAME}\"\necho \"  Region Emoji: ${REGION_EMOJI}\"\necho \"  K8s Environment: ${K8S_ENV}\"\necho \"‚úÖ Environment mapping completed successfully\"\n\n# Export variables for use in subsequent steps\necho \"DYNAMIC_AGENT_UUID=${AGENT_UUID}\"\necho \"DYNAMIC_AGENT_NAME=${AGENT_NAME}\"\necho \"DYNAMIC_REGION=${REGION}\"\necho \"DYNAMIC_REGION_NAME=${REGION_NAME}\"\necho \"DYNAMIC_REGION_EMOJI=${REGION_EMOJI}\"\necho \"DYNAMIC_K8S_ENV=${K8S_ENV}\"\n",
      "description": "Map Datadog environment to appropriate agent configuration",
      "executor": {
        "type": "command",
        "config": {}
      },
      "output": "agent_mapping"
    },
    {
      "name": "extract-agent-name",
      "description": "Extract agent name from mapping output",
      "executor": {
        "type": "command",
        "config": {}
      },
      "command": "echo \"${agent_mapping}\" | grep 'DYNAMIC_AGENT_NAME=' | cut -d'=' -f2",
      "depends": ["map-environment-to-agent"],
      "output": "agent_name"
    },
    {
      "name": "extract-agent-uuid", 
      "description": "Extract agent UUID from mapping output",
      "executor": {
        "type": "command",
        "config": {}
      },
      "command": "echo \"${agent_mapping}\" | grep 'DYNAMIC_AGENT_UUID=' | cut -d'=' -f2",
      "depends": ["map-environment-to-agent"],
      "output": "agent_uuid"
    },
    {
      "name": "extract-region-name",
      "description": "Extract region name from mapping output", 
      "executor": {
        "type": "command",
        "config": {}
      },
      "command": "echo \"${agent_mapping}\" | grep 'DYNAMIC_REGION_NAME=' | cut -d'=' -f2",
      "depends": ["map-environment-to-agent"],
      "output": "region_name"
    },
    {
      "name": "extract-region-emoji",
      "description": "Extract region emoji from mapping output",
      "executor": {
        "type": "command", 
        "config": {}
      },
      "command": "echo \"${agent_mapping}\" | grep 'DYNAMIC_REGION_EMOJI=' | cut -d'=' -f2",
      "depends": ["map-environment-to-agent"],
      "output": "region_emoji"
    },
    {
      "name": "validate-incident",
      "command": "echo \"\ud83d\udd0d VALIDATING INCIDENT PARAMETERS\"\necho \"=================================\"\nVALIDATION_PASSED=true\nMISSING_PARAMS=\"\"\n\nif [ -z \"${incident_id}\" ]; then\n  echo \"\u274c ERROR: incident_id is required\"\n  VALIDATION_PASSED=false\n  MISSING_PARAMS=\"${MISSING_PARAMS} incident_id\"\nfi\n\nif [ -z \"${incident_title}\" ]; then\n  echo \"\u274c ERROR: incident_title is required\"\n  VALIDATION_PASSED=false\n  MISSING_PARAMS=\"${MISSING_PARAMS} incident_title\"\nfi\n\nif [ -z \"${incident_severity}\" ]; then\n  echo \"\u274c ERROR: incident_severity is required\"\n  VALIDATION_PASSED=false\n  MISSING_PARAMS=\"${MISSING_PARAMS} incident_severity\"\nfi\n\nif [ -z \"${affected_services}\" ]; then\n  echo \"\u26a0\ufe0f WARNING: affected_services not provided - will create validation agent\"\nfi\n\ncase \"${incident_severity}\" in\n  \"critical\"|\"high\"|\"medium\"|\"low\")\n    echo \"\u2705 Severity ${incident_severity} is valid\"\n    ;;\n  *)\n    echo \"\u274c ERROR: Invalid severity ${incident_severity}. Must be: critical, high, medium, or low\"\n    VALIDATION_PASSED=false\n    MISSING_PARAMS=\"${MISSING_PARAMS} valid_severity\"\n    ;;\nesac\n\nif [ \"$VALIDATION_PASSED\" = \"true\" ]; then\n  echo \"\ud83d\udccb INCIDENT METADATA:\"\n  echo \"  ID: ${incident_id}\"\n  echo \"  Title: ${incident_title}\"\n  echo \"  Severity: ${incident_severity}\"\n  echo \"  Priority: ${incident_priority}\"\n  echo \"  Owner: ${incident_owner}\"\n  echo \"  Source: ${incident_source}\"\n  echo \"  Affected Services: ${affected_services:-TBD via agent}\"\n  echo \"  Customer Impact: ${customer_impact}\"\n  echo \"\"\n  echo \"\u2705 Incident validation completed successfully\"\nelse\n  echo \"\u274c Validation failed. Missing parameters: ${MISSING_PARAMS}\"\n  echo \"\u26a0\ufe0f Continuing workflow to handle validation failure...\"\nfi\n",
      "description": "Validate incident parameters and prerequisites",
      "executor": {
        "type": "command",
        "config": {}
      },
      "depends": [
        "extract-region-emoji"
      ],
      "output": "validation_status"
    },
    {
      "name": "normalize-channel-name",
      "description": "Normalize the channel name by replacing spaces with underscores and converting to lower case",
      "command": "if [ \"${normalize_channel_name:-true}\" = \"true\" ]; then\n  # Replace spaces with underscores, then convert to lower case\n  echo \"${slack_channel_id}\" | sed 's/ /_/g' | tr '[:upper:]' '[:lower:]'\nelse\n  # Only convert to lower case\n  echo \"${slack_channel_id}\" | tr '[:upper:]' '[:lower:]'\nfi\n",
      "depends": [
        "validate-incident"
      ],
      "executor": {
        "type": "command",
        "config": {}
      },
      "output": "NORMALIZED_CHANNEL_NAME"
    },
    {
      "name": "setup-slack-integration",
      "description": "Initialize Slack integration for incident communications",
      "executor": {
        "type": "kubiya",
        "config": {
          "url": "api/v1/integration/slack/token/1",
          "method": "GET",
          "silent": false
        }
      },
      "depends": [
        "normalize-channel-name"
      ],
      "output": "slack_token"
    },
    {
      "name": "validation_failure_message",
      "command": "if [ \"$VALIDATION_PASSED\" != \"true\" ]; then\n  echo \"\u26a0\ufe0f VALIDATION FAILURE DETECTED: Creating support agent to help\"\n  echo \"Missing required parameters: ${MISSING_PARAMS}\"\n  echo \"Will create an intelligent agent to assist with parameter collection\"\nelse\n  echo \"\u2705 All required parameters present\"\nfi\n",
      "description": "Prepare validation failure message if parameters are missing",
      "executor": {
        "type": "command",
        "config": {}
      },
      "depends": [
        "setup-slack-integration"
      ],
      "output": "validation_failure_message"
    },
    {
      "name": "prepare-agent-context",
      "command": "echo \"\ud83d\udd0d PREPARING AGENT CONTEXT\"\necho \"========================\"\nREGION_FOLLOWUP_PROMPT=\"Investigate production incident ${incident_id} - ${incident_title} (${incident_severity} severity) affecting ${affected_services} in ${region_name}.\"\necho \"REGION_FOLLOWUP_PROMPT=${REGION_FOLLOWUP_PROMPT}\"\necho \"\u2705 Agent context prepared successfully\"\n",
      "description": "Prepare simplified context for agent interactions",
      "executor": {
        "type": "command",
        "config": {}
      },
      "depends": [
        "setup-slack-integration"
      ],
      "output": "agent_context"
    },
    {
      "name": "post-incident-alert",
      "command": "echo \"\ud83d\udea8 POSTING INCIDENT ALERT\"\necho \"========================\"\n\n# Check if we have a Slack token\nif [ -z \"${slack_token}\" ] || [ \"${slack_token}\" = \"null\" ]; then\n  echo \"\u26a0\ufe0f No Slack token available - skipping Slack alert\"\n  echo \"\u2705 Incident alert skipped (no Slack integration)\"\n  exit 0\nfi\n\n# Set severity emoji\nSEVERITY_EMOJI=\"\"\ncase \"${incident_severity}\" in\n  critical) SEVERITY_EMOJI=\"\ud83d\udd34\" ;;\n  high) SEVERITY_EMOJI=\"\ud83d\udfe0\" ;;\n  medium) SEVERITY_EMOJI=\"\ud83d\udfe1\" ;;\n  low) SEVERITY_EMOJI=\"\ud83d\udfe2\" ;;\n  *) SEVERITY_EMOJI=\"\u26aa\" ;;\nesac\n\necho \"Posting to channel: ${NORMALIZED_CHANNEL_NAME}\"\necho \"Using severity emoji: ${SEVERITY_EMOJI} for ${incident_severity}\"\n\n# Create incident alert payload\nPAYLOAD=\"{\\\"channel\\\":\\\"${NORMALIZED_CHANNEL_NAME}\\\",\\\"text\\\":\\\"\ud83d\udea8 INCIDENT: ${incident_title}\\\",\\\"blocks\\\":[{\\\"type\\\":\\\"header\\\",\\\"text\\\":{\\\"type\\\":\\\"plain_text\\\",\\\"text\\\":\\\"\ud83d\udea8 Received incident to triage in PRODUCTION!\\\",\\\"emoji\\\":true}},{\\\"type\\\":\\\"section\\\",\\\"text\\\":{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"*${incident_title}*\\\"}},{\\\"type\\\":\\\"section\\\",\\\"fields\\\":[{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"*ID:* ${incident_id}\\\"},{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"*Severity:* ${SEVERITY_EMOJI} ${incident_severity}\\\"},{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"*Priority:* ${incident_priority:-Not Set}\\\"},{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"*Services:* ${affected_services}\\\"}]},{\\\"type\\\":\\\"divider\\\"},{\\\"type\\\":\\\"section\\\",\\\"text\\\":{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"${incident_body}\\\"}},{\\\"type\\\":\\\"divider\\\"},{\\\"type\\\":\\\"actions\\\",\\\"elements\\\":[{\\\"type\\\":\\\"button\\\",\\\"text\\\":{\\\"type\\\":\\\"plain_text\\\",\\\"text\\\":\\\"\ud83d\udcca View on Datadog\\\",\\\"emoji\\\":true},\\\"url\\\":\\\"${incident_url}\\\",\\\"style\\\":\\\"primary\\\"}]},{\\\"type\\\":\\\"context\\\",\\\"elements\\\":[{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"\u26a1 AI investigation will begin automatically in a few seconds...\\\"}]}]}\"\n\necho \"Posting alert to Slack...\"\nRESPONSE=$(curl -s -X POST https://slack.com/api/chat.postMessage \\\n  -H \"Authorization: Bearer ${slack_token.token}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"${PAYLOAD}\")\n\necho \"Slack API Response: ${RESPONSE}\"\n\nif echo \"${RESPONSE}\" | grep -q '\"ok\":true'; then\n  echo \"\u2705 Incident alert posted successfully to Slack!\"\nelse\n  echo \"\u26a0\ufe0f Failed to post incident alert to Slack - continuing workflow\"\n  echo \"Response: ${RESPONSE}\"\nfi\n\necho \"\u2705 Alert step completed (with or without Slack)\"\n",
      "description": "Send beautiful incident alert to Slack when services are provided",
      "executor": {
        "type": "command",
        "config": {}
      },
      "depends": [
        "prepare-agent-context"
      ],
      "output": "initial_alert_message",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "notify-investigation-progress",
      "command": "echo \"\ud83d\udcca POSTING INVESTIGATION PROGRESS UPDATE\"\necho \"=======================================\"\n\n# Check if we have Slack token and only post if available\nif [ -z \"${slack_token}\" ] || [ \"${slack_token}\" = \"null\" ]; then\n  echo \"\u26a0\ufe0f No Slack token available - skipping progress notification\"\n  echo \"\u2705 Investigation progress notification skipped\"\n  exit 0\nfi\n\necho \"Posting to channel: ${NORMALIZED_CHANNEL_NAME}\"\n\nTIMEOUT_SECONDS=\"${investigation_timeout:-3600}\"\nTIMEOUT_MINUTES=$((TIMEOUT_SECONDS / 60))\n\nPAYLOAD=\"{\\\"channel\\\":\\\"${NORMALIZED_CHANNEL_NAME}\\\",\\\"text\\\":\\\"\ud83d\udd0d AI Investigation Started\\\",\\\"blocks\\\":[{\\\"type\\\":\\\"section\\\",\\\"text\\\":{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"\ud83d\udd0d *AI Investigation Started*\\\\n${incident_title}\\\"}},{\\\"type\\\":\\\"context\\\",\\\"elements\\\":[{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"ID: ${incident_id} | Severity: ${incident_severity} | Services: ${affected_services}\\\"}]},{\\\"type\\\":\\\"divider\\\"},{\\\"type\\\":\\\"section\\\",\\\"text\\\":{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"*${region_emoji} ${region} Agent*\\\\n\ud83d\udfe2 Analyzing ${region} Production cluster...\\\"}},{\\\"type\\\":\\\"context\\\",\\\"elements\\\":[{\\\"type\\\":\\\"mrkdwn\\\",\\\"text\\\":\\\"\u23f1\ufe0f ETA: ~${TIMEOUT_MINUTES} minutes | \ud83d\udca1 Partial results will be provided even if steps fail\\\"}]}]}\"\n\nRESPONSE=$(curl -s -X POST https://slack.com/api/chat.postMessage \\\n  -H \"Authorization: Bearer ${slack_token.token}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"${PAYLOAD}\")\n\nif echo \"${RESPONSE}\" | grep -q '\"ok\":true'; then\n  echo \"\u2705 Investigation progress notification posted to Slack\"\nelse\n  echo \"\u26a0\ufe0f Investigation progress posting failed (continuing workflow)\"\n  echo \"Response: ${RESPONSE}\"\nfi\n\necho \"\u2705 Progress notification step completed\"\n",
      "description": "Post consolidated investigation progress update",
      "executor": {
        "type": "command",
        "config": {}
      },
      "depends": [
        "post-incident-alert"
      ],
      "output": "investigation_progress_message",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "prepare-investigation-instructions",
      "description": "Prepare detailed investigation instructions for the agent",
      "executor": {
        "type": "command",
        "config": {}
      },
      "command": "cat << 'EOF'\nüö® PRODUCTION INCIDENT INVESTIGATION - ${region_name}\n\n**INCIDENT DETAILS:**\n- **Public ID:** ${incident_id}\n- **Title:** ${incident_title}\n- **Severity:** ${incident_severity}\n- **Priority:** ${incident_priority}\n- **Customer Impact:** ${customer_impact}\n- **Affected Services:** ${affected_services}\n\n**INVESTIGATION CHECKLIST:**\n\n### 1. CLUSTER HEALTH & NODES\nkubectl get nodes -o wide\nkubectl describe nodes | grep -E \"Conditions|Capacity|Allocatable\"\nkubectl top nodes\nkubectl get events --sort-by='.lastTimestamp' | tail -20\n\n### 2. POD STATUS & HEALTH\nkubectl get pods --all-namespaces -o wide | grep -v Running | head -20\nkubectl get pods -n production -o wide | grep -E \"Error|CrashLoop|Pending|Failed\"\nkubectl describe pods -n production | grep -E \"Warning|Error|Failed\" | head -30\nkubectl top pods -n production --sort-by=cpu | head -10\n\n### 3. SERVICE DISCOVERY & NETWORKING\nkubectl get svc --all-namespaces\nkubectl get ingress --all-namespaces\nkubectl get endpoints --all-namespaces | grep -v \"<none>\"\nnslookup kubernetes.default.svc.cluster.local\n\n### 4. APPLICATION SPECIFIC CHECKS\nkubectl logs deployment/${affected_services} -n production --tail=50 | grep -E \"ERROR|WARN|FATAL|Exception\"\nkubectl describe deployment ${affected_services} -n production | grep -E \"Warning|Error|Failed|Ready\"\nkubectl get hpa,pdb -n production | grep ${affected_services}\nkubectl exec deployment/${affected_services} -n production -- curl -s localhost:8080/health | head -10\n\n### 5. RESOURCE UTILIZATION\nkubectl top pods -n production --containers\nkubectl describe limits -n production\nkubectl get pvc -n production -o wide\ndf -h\n\n**INVESTIGATION REQUEST:**\nPlease conduct a thorough investigation of this ${incident_severity} severity incident affecting ${affected_services}. Provide detailed analysis, root cause identification, and actionable remediation steps.\nEOF",
      "depends": [
        "notify-investigation-progress"
      ],
      "output": "investigation_instructions"
    },
    {
      "name": "investigate-cluster-health-na",
      "description": "AI-powered incident investigation for NA production",
      "executor": {
        "type": "agent",
        "config": {
          "agent_name": "chatops-na",
          "message": "Production Incident Investigation Required. Alert ID: $ALERT_ID. Status: $ALERT_STATUS. Priority: $ALERT_PRIORITY. Incident: $INCIDENT_MSG. Environment: $TAGS[environment]. All Tags: $TAGS. Hostname: $HOSTNAME. Please conduct thorough investigation including cluster health, pod status, logs analysis, and provide root cause with remediation steps."
        }
      },
      "depends": [
        "prepare-investigation-instructions"
      ],
      "preconditions": {
        "conditions": [
          {
            "field": "${datadog_environment}",
            "operator": "equals",
            "value": "na-production"
          }
        ]
      },
      "output": "cluster_results",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "investigate-cluster-health-eu",
      "description": "AI-powered incident investigation for EU production",
      "executor": {
        "type": "agent",
        "config": {
          "agent_name": "chatops-eu",
          "message": "Production Incident Investigation Required. Alert ID: $ALERT_ID. Status: $ALERT_STATUS. Priority: $ALERT_PRIORITY. Incident: $INCIDENT_MSG. Environment: $TAGS[environment]. All Tags: $TAGS. Hostname: $HOSTNAME. Please conduct thorough investigation including cluster health, pod status, logs analysis, and provide root cause with remediation steps."
        }
      },
      "depends": [
        "prepare-investigation-instructions"
      ],
      "preconditions": {
        "conditions": [
          {
            "field": "${datadog_environment}",
            "operator": "equals",
            "value": "eu-production"
          }
        ]
      },
      "output": "cluster_results",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "investigate-cluster-health-na-int",
      "description": "AI-powered incident investigation for NA integration",
      "executor": {
        "type": "agent",
        "config": {
          "agent_name": "chatops-na-integration",
          "message": "Production Incident Investigation Required. Alert ID: $ALERT_ID. Status: $ALERT_STATUS. Priority: $ALERT_PRIORITY. Incident: $INCIDENT_MSG. Environment: $TAGS[environment]. All Tags: $TAGS. Hostname: $HOSTNAME. Please conduct thorough investigation including cluster health, pod status, logs analysis, and provide root cause with remediation steps."
        }
      },
      "depends": [
        "prepare-investigation-instructions"
      ],
      "preconditions": {
        "conditions": [
          {
            "field": "${datadog_environment}",
            "operator": "equals",
            "value": "na-integration"
          }
        ]
      },
      "output": "cluster_results",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "create-executive-summary-na",
      "description": "Create executive summary for NA production investigation",
      "executor": {
        "type": "agent",
        "config": {
          "agent_name": "chatops-na",
          "message": "Create Executive Summary. Alert ID: $ALERT_ID. Incident: $INCIDENT_MSG. Environment: $TAGS[environment]. Tags: $TAGS. Investigation Results: ${cluster_results}. Based on these investigation results, provide comprehensive executive summary including incident overview, key findings, root cause analysis, impact assessment, and recommended actions for stakeholders."
        }
      },
      "depends": [
        "investigate-cluster-health-na"
      ],
      "preconditions": {
        "conditions": [
          {
            "field": "${datadog_environment}",
            "operator": "equals",
            "value": "na-production"
          }
        ]
      },
      "output": "executive_summary",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "create-executive-summary-eu",
      "description": "Create executive summary for EU production investigation",
      "executor": {
        "type": "agent",
        "config": {
          "agent_name": "chatops-eu",
          "message": "Create Executive Summary. Alert ID: $ALERT_ID. Incident: $INCIDENT_MSG. Environment: $TAGS[environment]. Tags: $TAGS. Investigation Results: ${cluster_results}. Based on these investigation results, provide comprehensive executive summary including incident overview, key findings, root cause analysis, impact assessment, and recommended actions for stakeholders."
        }
      },
      "depends": [
        "investigate-cluster-health-eu"
      ],
      "preconditions": {
        "conditions": [
          {
            "field": "${datadog_environment}",
            "operator": "equals",
            "value": "eu-production"
          }
        ]
      },
      "output": "executive_summary",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "create-executive-summary-na-int",
      "description": "Create executive summary for NA integration investigation",
      "executor": {
        "type": "agent",
        "config": {
          "agent_name": "chatops-na-integration",
          "message": "Create Executive Summary. Alert ID: $ALERT_ID. Incident: $INCIDENT_MSG. Environment: $TAGS[environment]. Tags: $TAGS. Investigation Results: ${cluster_results}. Based on these investigation results, provide comprehensive executive summary including incident overview, key findings, root cause analysis, impact assessment, and recommended actions for stakeholders."
        }
      },
      "depends": [
        "investigate-cluster-health-na-int"
      ],
      "preconditions": {
        "conditions": [
          {
            "field": "${datadog_environment}",
            "operator": "equals",
            "value": "na-integration"
          }
        ]
      },
      "output": "executive_summary",
      "continueOn": {
        "failure": true
      }
    },
    {
      "name": "post-investigation-summary",
      "description": "Post investigation summary to Slack using block kit",
      "depends": [
        "create-executive-summary-na",
        "create-executive-summary-eu", 
        "create-executive-summary-na-int"
      ],
      "executor": {
        "type": "command",
        "config": {}
      },
      "command": "echo 'üìã POSTING INVESTIGATION SUMMARY TO SLACK' && echo '=======================================' && if [ -z '${slack_token}' ] || [ '${slack_token}' = 'null' ]; then echo '‚ö†Ô∏è No Slack token available - skipping summary post' && echo '‚úÖ Summary post skipped (no Slack integration)' && exit 0; fi && SEVERITY_EMOJI='' && case '${incident_severity}' in critical) SEVERITY_EMOJI='üî¥' ;; high) SEVERITY_EMOJI='üü†' ;; medium) SEVERITY_EMOJI='üü°' ;; low) SEVERITY_EMOJI='üü¢' ;; *) SEVERITY_EMOJI='‚ö™' ;; esac && cat > /tmp/slack_payload.json << EOF\n{\n  \"channel\": \"${NORMALIZED_CHANNEL_NAME}\",\n  \"text\": \"‚úÖ AI Investigation Complete\",\n  \"blocks\": [\n    {\n      \"type\": \"header\",\n      \"text\": {\n        \"type\": \"plain_text\",\n        \"text\": \"üö® INCIDENT INVESTIGATION COMPLETE\",\n        \"emoji\": true\n      }\n    },\n    {\n      \"type\": \"section\",\n      \"fields\": [\n        {\n          \"type\": \"mrkdwn\",\n          \"text\": \"*Alert ID:* $ALERT_ID\"\n        },\n        {\n          \"type\": \"mrkdwn\",\n          \"text\": \"*Status:* $ALERT_STATUS\"\n        },\n        {\n          \"type\": \"mrkdwn\",\n          \"text\": \"*Priority:* $ALERT_PRIORITY\"\n        },\n        {\n          \"type\": \"mrkdwn\",\n          \"text\": \"*Environment:* $TAGS[environment]\"\n        }\n      ]\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"*üîç Investigation Summary:*\\n${executive_summary}\"\n      }\n    },\n    {\n      \"type\": \"divider\"\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"*üìä Full Investigation Results:*\\n${cluster_results}\"\n      }\n    },\n    {\n      \"type\": \"divider\"\n    },\n    {\n      \"type\": \"actions\",\n      \"elements\": [\n        {\n          \"type\": \"button\",\n          \"text\": {\n            \"type\": \"plain_text\",\n            \"text\": \"üîó View Datadog Alert\",\n            \"emoji\": true\n          },\n          \"url\": \"$LINK\",\n          \"style\": \"primary\"\n        },\n        {\n          \"type\": \"button\",\n          \"text\": {\n            \"type\": \"plain_text\",\n            \"text\": \"üìã Follow Up Investigation\",\n            \"emoji\": true\n          },\n          \"value\": \"investigate_further\",\n          \"action_id\": \"investigate_further\"\n        }\n      ]\n    }\n  ]\n}\nEOF\necho 'Posting enhanced summary to Slack...' && curl -s -X POST https://slack.com/api/chat.postMessage -H 'Authorization: Bearer ${slack_token.token}' -H 'Content-Type: application/json' -d @/tmp/slack_payload.json && echo '‚úÖ Investigation summary posted successfully to Slack!'",
      "output": "summary_post_status",
      "continueOn": {
        "failure": true
      }
    }
  ]
}
